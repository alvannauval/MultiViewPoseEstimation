{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ac7016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "frame = []\n",
    "\n",
    "\n",
    "\n",
    "tf_0 = np.load(r'PCD_Data/view00_tf.npy')\n",
    "tf_obj = np.load(r'PCD_Data/initial_obj_pose.npy')\n",
    "pcd_0 = o3d.io.read_point_cloud(r\"PCD_Data/view00.pcd\")\n",
    "\n",
    "\n",
    "tf_0_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=50.0)\n",
    "tf_0_frame.transform(tf_0)\n",
    "object_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=tf_obj[:3])\n",
    "\n",
    "frame.append(tf_0_frame)\n",
    "frame.append(object_frame)\n",
    "\n",
    "# # Load the numpy file\n",
    "# tf_0 = np.load(r'PCD_Data/view00_tf.npy')\n",
    "# tf_1 = np.load(r'PCD_Data/view01_tf.npy')\n",
    "# tf_2 = np.load(r'PCD_Data/view02_tf.npy')\n",
    "# tf_3 = np.load(r'PCD_Data/view03_tf.npy')\n",
    "# tf_4 = np.load(r'PCD_Data/view04_tf.npy')\n",
    "# tf_5 = np.load(r'PCD_Data/view05_tf.npy')\n",
    "# tf_6 = np.load(r'PCD_Data/view06_tf.npy')\n",
    "# tf_7 = np.load(r'PCD_Data/view07_tf.npy')\n",
    "# tf_8 = np.load(r'PCD_Data/view08_tf.npy')\n",
    "# tf_obj = np.load(r'PCD_Data/initial_obj_pose.npy')\n",
    "\n",
    "# # Load pcd files\n",
    "# pcd_0 = o3d.io.read_point_cloud(r\"PCD_Data/view00.pcd\")\n",
    "# # pcd_1 = o3d.io.read_point_cloud(r\"PCD_Data/new_tf_down/view01.pcd\")\n",
    "# # pcd_2 = o3d.io.read_point_cloud(r\"PCD_Data/new_tf_down/view02.pcd\")\n",
    "# # pcd_3 = o3d.io.read_point_cloud(r\"PCD_Data/new_tf_down/view03.pcd\")\n",
    "# # pcd_4 = o3d.io.read_point_cloud(r\"PCD_Data/new_tf_down/view04.pcd\")\n",
    "\n",
    "\n",
    "# tf_0_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=50.0)\n",
    "# tf_0_frame.transform(tf_0)\n",
    "# tf_1_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_1_frame.transform(tf_1)\n",
    "# tf_2_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_2_frame.transform(tf_2)\n",
    "# tf_3_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_3_frame.transform(tf_3)\n",
    "# tf_4_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_4_frame.transform(tf_4)\n",
    "# tf_5_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_5_frame.transform(tf_5)\n",
    "# tf_6_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_6_frame.transform(tf_6)\n",
    "# tf_7_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_7_frame.transform(tf_7)\n",
    "# tf_8_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_8_frame.transform(tf_8)\n",
    "# frame.append(tf_0_frame)\n",
    "# frame.append(tf_1_frame)\n",
    "# frame.append(tf_2_frame)\n",
    "# frame.append(tf_3_frame)\n",
    "# frame.append(tf_4_frame)\n",
    "# frame.append(tf_5_frame)\n",
    "# frame.append(tf_6_frame)\n",
    "# frame.append(tf_7_frame)\n",
    "# frame.append(tf_8_frame)\n",
    "\n",
    "\n",
    "# pasti ada\n",
    "object_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=tf_obj[:3])\n",
    "frame.append(object_frame)\n",
    "\n",
    "world_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=[0, 0, 0])\n",
    "frame.append(world_frame)\n",
    "\n",
    "\n",
    "# test_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=[517.8511039561226, 163.59750883586588, 600.0])\n",
    "# frame.append(test_frame)\n",
    "\n",
    "o3d.visualization.draw_geometries(frame + [pcd_0])\n",
    "# o3d.visualization.draw_geometries(frame + [pcd_0, pcd_1, pcd_2, pcd_3, pcd_4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c43a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "\n",
    "\n",
    "def get_rotation_matrix_z(deg):\n",
    "    \"\"\"Creates a 3x3 rotation matrix for the Z-axis.\"\"\"\n",
    "    rad = math.radians(deg)\n",
    "    c, s = math.cos(rad), math.sin(rad)\n",
    "    return np.array([[c, -s, 0], \n",
    "                     [s,  c, 0], \n",
    "                     [0,  0, 1]])\n",
    "\n",
    "\n",
    "def merge_multiview_scan(data_dir, initial_pos, initial_angle, box_size):\n",
    "    \"\"\"Merges multiple view PCDs and removes points below the detected plane.\"\"\"\n",
    "    pcd_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.pcd') and \"view0\" in f])\n",
    "    merged_pcd = o3d.geometry.PointCloud()\n",
    "    \n",
    "    obb = o3d.geometry.OrientedBoundingBox(\n",
    "        center=np.array(initial_pos), \n",
    "        R=get_rotation_matrix_z(-initial_angle), \n",
    "        extent=np.array(box_size)\n",
    "    )\n",
    "\n",
    "    for file_name in pcd_files:\n",
    "        pcd = o3d.io.read_point_cloud(os.path.join(data_dir, file_name))\n",
    "   \n",
    "        # 1. Detect the plane\n",
    "        plane_model, inliers = pcd.segment_plane(distance_threshold=3.0, ransac_n=3, num_iterations=2000)\n",
    "        [a, b, c, d] = plane_model\n",
    "\n",
    "        # 2. Extract all points as a numpy array\n",
    "        pts = np.asarray(pcd.points)\n",
    "\n",
    "        # 3. Calculate distance to plane for every point: ax + by + cz + d\n",
    "        # Points on the plane result in 0. Points above are positive, below are negative.\n",
    "        distances = a * pts[:, 0] + b * pts[:, 1] + c * pts[:, 2] + d\n",
    "        \n",
    "        # 4. Create an index of points that are ABOVE the plane\n",
    "        # A small offset (e.g., 0.5mm) to avoid keeping table noise\n",
    "        above_plane_indices = np.where(distances > 0.5)[0]\n",
    "        pcd = pcd.select_by_index(above_plane_indices)\n",
    "\n",
    "        # 5. Crop to the OBB and merge\n",
    "        merged_pcd += pcd.crop(obb)\n",
    "\n",
    "    return merged_pcd\n",
    "\n",
    "\n",
    "def preprocess_point_cloud(pcd, num_points):\n",
    "    \"\"\"Downsamples, estimates normals, and computes FPFH features.\"\"\"\n",
    "    pcd_down = pcd.farthest_point_down_sample(num_points)\n",
    "    avg_dist = np.mean(pcd_down.compute_nearest_neighbor_distance())\n",
    "    \n",
    "    # Estimate Normals\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=avg_dist * 2, max_nn=30))\n",
    "    \n",
    "    # Orientation fix: Ensure normals point 'up' (positive Z)\n",
    "    normals = np.asarray(pcd_down.normals)\n",
    "    for i in range(len(normals)):\n",
    "        if normals[i][2] < 0:\n",
    "            normals[i] *= -1\n",
    "\n",
    "    # Compute FPFH (Feature descriptors for global matching)\n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down, o3d.geometry.KDTreeSearchParamHybrid(radius=avg_dist * 5, max_nn=100))\n",
    "    \n",
    "    return pcd_down, fpfh\n",
    "\n",
    "\n",
    "def run_global_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    \"\"\"\n",
    "    Performs RANSAC-based global registration to find a rough alignment.\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    \n",
    "    # RANSAC based on feature matching\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source, target, source_fpfh, target_fpfh, \n",
    "        mutual_filter=True,\n",
    "        max_correspondence_distance=distance_threshold,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        ransac_n=3, \n",
    "        checkers=[\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "        ], \n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "def run_global_registration_adaptive(source_down, target_down, source_fpfh, target_fpfh):\n",
    "    \"\"\"\n",
    "    Performs iterative RANSAC-based global registration to find the best rough alignment.\n",
    "    Matches the logic of testing multiple thresholds to find the highest fitness and lowest RMSE.\n",
    "    \"\"\"\n",
    "    max_attempts = 5\n",
    "    best_fitness = -0.1\n",
    "    best_inlier_rmse = 100.0\n",
    "    best_result = None\n",
    "    best_threshold = None \n",
    "\n",
    "    # Thresholds to test, from coarse (10.0) to fine (3.0)\n",
    "    thresholds = [10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0]\n",
    "    # thresholds = [7]\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "        for thr in thresholds:            \n",
    "            result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "                source_down, target_down, source_fpfh, target_fpfh, \n",
    "                mutual_filter=True, # Improved matching\n",
    "                max_correspondence_distance=thr,\n",
    "                estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "                ransac_n=3, \n",
    "                checkers=[\n",
    "                    o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.85),\n",
    "                    o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(thr)\n",
    "                ], \n",
    "                criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(10000, 0.99)\n",
    "            )\n",
    "\n",
    "            # Update best result if fitness is good and RMSE is lower\n",
    "            if result.fitness > 0.85 and result.inlier_rmse < best_inlier_rmse:\n",
    "                best_fitness = result.fitness\n",
    "                best_inlier_rmse = result.inlier_rmse\n",
    "                best_result = result\n",
    "                best_threshold = thr\n",
    "            \n",
    "            # Early exit if we find a very high-quality match\n",
    "            if best_fitness > 0.95 and best_inlier_rmse < 2.35: \n",
    "                print(f\"Excellent Global Fit Found at Threshold {best_threshold}\")\n",
    "                return best_result, best_threshold\n",
    "            \n",
    "    if best_result is None:\n",
    "        print(\"Warning: RANSAC could not find a fit above 0.85 fitness.\")\n",
    "        # Fallback to the last result generated if nothing met the 0.85 criteria\n",
    "        return result, thr\n",
    "\n",
    "    print(f\"RANSAC Finished. Best Threshold: {best_threshold} | Fitness: {best_fitness:.4f}\")\n",
    "    return best_result, best_threshold\n",
    "\n",
    "\n",
    "# One time local refinement using ICP\n",
    "def run_local_refinement(source, target, initial_transformation, voxel_size):\n",
    "    \"\"\"\n",
    "    Performs ICP registration to refine the alignment found by RANSAC.\n",
    "    \"\"\"\n",
    "    # We use a smaller threshold for ICP to ensure high precision\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    \n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, initial_transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "# Progressive Local Refinement using ICP\n",
    "def run_local_refinement_adaptive(source, target, initial_trans, best_ransac_thr):\n",
    "    \"\"\"\n",
    "    Refines alignment using an iterative ICP loop. \n",
    "    Starts with a coarse threshold and progressively tightens for precision.\n",
    "    \"\"\"\n",
    "    # Define a range of multipliers to tighten the search radius\n",
    "    # multipliers = [1.0, 0.8, 0.5, 0.25]\n",
    "    multipliers = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    # multipliers = [0.6]\n",
    "    thresholds = [best_ransac_thr * m for m in multipliers]\n",
    "    \n",
    "    best_result = None\n",
    "    best_inlier_rmse = float('inf') # Start with the highest possible error\n",
    "    \n",
    "    print(f\"{'Threshold':<12} | {'Fitness':<12} | {'RMSE':<12}\")\n",
    "    print(\"-\" * 45)\n",
    "\n",
    "    for thr in thresholds:\n",
    "        # Execute Point-to-Point ICP\n",
    "        reg_icp = o3d.pipelines.registration.registration_icp(\n",
    "            source, target, thr, initial_trans,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=1000)\n",
    "        )\n",
    "\n",
    "        # Logging the current iteration results\n",
    "        print(f\"{thr:<12.2f} | {reg_icp.fitness:<12.4f} | {reg_icp.inlier_rmse:<12.4f}\")\n",
    "\n",
    "        # Selection Logic: Prioritize lowest RMSE (highest precision) \n",
    "        # as long as the fitness is acceptable (e.g., > 85%)\n",
    "        if reg_icp.fitness > 0.85 and reg_icp.inlier_rmse < best_inlier_rmse:\n",
    "            best_inlier_rmse = reg_icp.inlier_rmse\n",
    "            best_result = reg_icp\n",
    "\n",
    "    # Fallback: if no run met the 85% fitness, return the last result\n",
    "    return best_result if best_result is not None else reg_icp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f14a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Merging and cleaning scans...\n"
     ]
    }
   ],
   "source": [
    "# Main Processing Pipeline\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "DATA_DIR = \"PCD_Data\"\n",
    "SOURCE_PATH = \"workpiece/z_bracket_10000.pcd\" #  CAD model\n",
    "\n",
    "tf_obj = np.load(r'PCD_Data/initial_obj_pose.npy')\n",
    "YOLO_POS = tf_obj[:3]                                   # Initial guess from YOLO\n",
    "YOLO_ANGLE = tf_obj[4]                                  # Initial angle from YOLO\n",
    "CROP_BOX = [85, 65, 60]                               # Region of interest size\n",
    "\n",
    "\n",
    "# --- 2. Data Preparation ---\n",
    "print(\"Step 1: Merging and cleaning scans...\")\n",
    "source_cloud = o3d.io.read_point_cloud(SOURCE_PATH)\n",
    "target_cloud = merge_multiview_scan(DATA_DIR, YOLO_POS, YOLO_ANGLE, CROP_BOX)\n",
    "o3d.visualization.draw_geometries([target_cloud], window_name=\"Merged Target Cloud\")\n",
    "\n",
    "# Get downsampled versions and features for RANSAC\n",
    "source_down, source_fpfh = preprocess_point_cloud(source_cloud, 10000)\n",
    "target_down, target_fpfh = preprocess_point_cloud(target_cloud, 10000)\n",
    "o3d.visualization.draw_geometries([source_down], window_name=\"Downsampled Source Cloud\")\n",
    "# o3d.visualization.draw_geometries([target_down], window_name=\"Downsampled Target Cloud\")\n",
    "\n",
    "\n",
    "# --- 3. Global Alignment (RANSAC) ---\n",
    "print(\"Step 2: Running RANSAC Global Registration...\")\n",
    "ransac_res, best_thr = run_global_registration_adaptive(source_down, target_down, source_fpfh, target_fpfh)\n",
    "print(ransac_res)\n",
    "\n",
    "# Visualize RANSAC result\n",
    "source_temp = copy.deepcopy(source_cloud)\n",
    "source_temp.transform(ransac_res.transformation)\n",
    "source_temp.paint_uniform_color([1, 0, 0])\n",
    "target_down.paint_uniform_color([0, 0.651, 0.929])\n",
    "o3d.visualization.draw_geometries([source_temp, target_down], window_name=\"RANSAC Result\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8791a78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Running ICP Local Refinement...\n",
      "Threshold    | Fitness      | RMSE        \n",
      "---------------------------------------------\n",
      "8.00         | 0.9981       | 2.4935      \n",
      "7.20         | 0.9932       | 2.4434      \n",
      "6.40         | 0.9826       | 2.3519      \n",
      "5.60         | 0.9695       | 2.2641      \n",
      "4.80         | 0.9428       | 2.1252      \n",
      "4.00         | 0.8951       | 1.9373      \n",
      "3.20         | 0.8091       | 1.6634      \n",
      "2.40         | 0.6628       | 1.3434      \n",
      "1.60         | 0.4905       | 1.0117      \n",
      "0.80         | 0.0974       | 0.6063      \n",
      "RegistrationResult with fitness=8.951000e-01, inlier_rmse=1.937284e+00, and correspondence_set size of 8951\n",
      "Access transformation to get result.\n",
      "==============================\n",
      "Final Position: [558.71748665 -62.17248791  -3.09258709]\n",
      "Final Orientation Matrix:\n",
      "[[-4.39091588e-01  8.98384702e-01  1.01736956e-02]\n",
      " [-8.98430342e-01 -4.39116027e-01  1.88217879e-04]\n",
      " [ 4.63652484e-03 -9.05771192e-03  9.99948229e-01]]\n",
      "Fitness: 0.8951\n",
      "RMSE: 1.9373\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Local Alignment (ICP) ---\n",
    "print(\"Step 3: Running ICP Local Refinement...\")\n",
    "icp_res = run_local_refinement_adaptive(source_cloud, target_down, ransac_res.transformation, best_thr)\n",
    "print(icp_res)\n",
    "\n",
    "# --- 5. Extract Final Results ---\n",
    "final_matrix = icp_res.transformation\n",
    "initial_POS = final_matrix[:3, 3] \n",
    "initial_ORI = final_matrix[:3, :3] \n",
    "print(\"=\"*30)\n",
    "print(f\"Final Position: {initial_POS}\")\n",
    "print(f\"Final Orientation Matrix:\\n{initial_ORI}\")\n",
    "print(f\"Fitness: {icp_res.fitness:.4f}\")\n",
    "print(f\"RMSE: {icp_res.inlier_rmse:.4f}\")\n",
    "\n",
    "\n",
    "# --- 6. Final Visualization ---\n",
    "source_final = copy.deepcopy(source_cloud).transform(final_matrix)\n",
    "source_final.paint_uniform_color([1, 0, 0])         # Red: CAD Model\n",
    "target_cloud.paint_uniform_color([0, 0.65, 0.93])   # Blue: Scanned Data\n",
    "o3d.visualization.draw_geometries([source_final, target_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decde6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# Use the correct reader for STL files\n",
    "mesh = o3d.io.read_triangle_mesh(r\"workpiece/first_object.stl\")\n",
    "\n",
    "# Add this to see the surface (STLs don't always have colors)\n",
    "# mesh.compute_vertex_normals()\n",
    "\n",
    "\n",
    "pcd = mesh.sample_points_uniformly(number_of_points=10000)\n",
    "pcd.paint_uniform_color([1, 0, 0])  # Red for the\n",
    "\n",
    "#  Visualize\n",
    "o3d.visualization.draw_geometries([mesh, pcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
