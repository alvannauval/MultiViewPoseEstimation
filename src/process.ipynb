{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac7016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "frame = []\n",
    "\n",
    "# Load the numpy file\n",
    "tf_0 = np.load(r'TestingData\\view00_tf.npy')\n",
    "tf_1 = np.load(r'TestingData\\view01_tf.npy')\n",
    "tf_2 = np.load(r'TestingData\\view02_tf.npy')\n",
    "tf_3 = np.load(r'TestingData\\view03_tf.npy')\n",
    "tf_4 = np.load(r'TestingData\\view04_tf.npy')\n",
    "tf_obj = np.load(r'TestingData\\initial_POS.npy')\n",
    "\n",
    "# Load pcd files\n",
    "pcd_0 = o3d.io.read_point_cloud(r\"TestingData\\view00.pcd\")\n",
    "pcd_1 = o3d.io.read_point_cloud(r\"TestingData\\view01.pcd\")\n",
    "pcd_2 = o3d.io.read_point_cloud(r\"TestingData\\view02.pcd\")\n",
    "pcd_3 = o3d.io.read_point_cloud(r\"TestingData\\view03.pcd\")\n",
    "pcd_4 = o3d.io.read_point_cloud(r\"TestingData\\view04.pcd\")\n",
    "\n",
    "\n",
    "world_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=[0, 0, 0])\n",
    "world_frame_x = o3d.geometry.TriangleMesh.create_coordinate_frame(size=75.0, origin=[20, 0, 0])\n",
    "world_frame_y = o3d.geometry.TriangleMesh.create_coordinate_frame(size=24.0, origin=[0, 20, 0])\n",
    "frame.append(world_frame)\n",
    "frame.append(world_frame_x)\n",
    "frame.append(world_frame_y)\n",
    "\n",
    "# tf_0_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_0_frame.transform(tf_0)\n",
    "# tf_1_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_1_frame.transform(tf_1)\n",
    "# tf_2_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_2_frame.transform(tf_2)\n",
    "# tf_3_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_3_frame.transform(tf_3)\n",
    "# tf_4_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0)\n",
    "# tf_4_frame.transform(tf_4)\n",
    "# frame.append(tf_0_frame)\n",
    "# frame.append(tf_1_frame)\n",
    "# frame.append(tf_2_frame)\n",
    "# frame.append(tf_3_frame)\n",
    "# frame.append(tf_4_frame)\n",
    "\n",
    "# object_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=tf_obj)\n",
    "# frame.append(object_frame)\n",
    "\n",
    "\n",
    "# o3d.visualization.draw_geometries(frame + [pcd_0])\n",
    "o3d.visualization.draw_geometries(frame + [pcd_0, pcd_1, pcd_2, pcd_3, pcd_4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "\n",
    "\n",
    "def get_rotation_matrix_z(deg):\n",
    "    \"\"\"Creates a 3x3 rotation matrix for the Z-axis.\"\"\"\n",
    "    rad = math.radians(deg)\n",
    "    c, s = math.cos(rad), math.sin(rad)\n",
    "    return np.array([[c, -s, 0], \n",
    "                     [s,  c, 0], \n",
    "                     [0,  0, 1]])\n",
    "\n",
    "\n",
    "def merge_multiview_scan(data_dir, initial_pos, initial_angle, box_size):\n",
    "    \"\"\"Merges multiple view PCDs into one target cloud within a bounding box.\"\"\"\n",
    "    pcd_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.pcd') and \"view0\" in f])\n",
    "    merged_pcd = o3d.geometry.PointCloud()\n",
    "    \n",
    "    # Setup Oriented Bounding Box (OBB) for cropping\n",
    "    obb = o3d.geometry.OrientedBoundingBox(\n",
    "        center = np.array(initial_pos), \n",
    "        R = get_rotation_matrix_z(-initial_angle), \n",
    "        extent = np.array(box_size)\n",
    "    )\n",
    "\n",
    "    for file_name in pcd_files:\n",
    "        pcd = o3d.io.read_point_cloud(os.path.join(data_dir, file_name))\n",
    "        \n",
    "        # Remove ground plane\n",
    "        _, inliers = pcd.segment_plane(distance_threshold=3.0, ransac_n=3, num_iterations=2000)\n",
    "        pcd = pcd.select_by_index(inliers, invert=True) \n",
    "        \n",
    "        # Crop to the area where the object is expected\n",
    "        merged_pcd += pcd.crop(obb)\n",
    "        \n",
    "    return merged_pcd\n",
    "\n",
    "\n",
    "def preprocess_point_cloud(pcd, num_points):\n",
    "    \"\"\"Downsamples, estimates normals, and computes FPFH features.\"\"\"\n",
    "    pcd_down = pcd.farthest_point_down_sample(num_points)\n",
    "    avg_dist = np.mean(pcd_down.compute_nearest_neighbor_distance())\n",
    "    \n",
    "    # Estimate Normals\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=avg_dist * 2, max_nn=30))\n",
    "    \n",
    "    # Orientation fix: Ensure normals point 'up' (positive Z)\n",
    "    normals = np.asarray(pcd_down.normals)\n",
    "    for i in range(len(normals)):\n",
    "        if normals[i][2] < 0:\n",
    "            normals[i] *= -1\n",
    "\n",
    "    # Compute FPFH (Feature descriptors for global matching)\n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down, o3d.geometry.KDTreeSearchParamHybrid(radius=avg_dist * 5, max_nn=100))\n",
    "    \n",
    "    return pcd_down, fpfh\n",
    "\n",
    "\n",
    "def run_global_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    \"\"\"\n",
    "    Performs RANSAC-based global registration to find a rough alignment.\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    \n",
    "    # RANSAC based on feature matching\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source, target, source_fpfh, target_fpfh, \n",
    "        mutual_filter=True,\n",
    "        max_correspondence_distance=distance_threshold,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        ransac_n=3, \n",
    "        checkers=[\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "        ], \n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "def run_global_registration_adaptive(source_down, target_down, source_fpfh, target_fpfh):\n",
    "    \"\"\"\n",
    "    Performs iterative RANSAC-based global registration to find the best rough alignment.\n",
    "    Matches the logic of testing multiple thresholds to find the highest fitness and lowest RMSE.\n",
    "    \"\"\"\n",
    "    max_attempts = 1\n",
    "    best_fitness = -0.1\n",
    "    best_inlier_rmse = 100.0\n",
    "    best_result = None\n",
    "    best_threshold = None \n",
    "\n",
    "    # Thresholds to test, from coarse (10.0) to fine (3.0)\n",
    "    # thresholds = [10.0, 9.5, 9.0, 8.5, 8.0, 7.5, 7.0, 6.5, 6.0, 5.5, 5.0, 4.5, 4.0, 3.5, 3.0]\n",
    "    thresholds = [7]\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "        for thr in thresholds:            \n",
    "            result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "                source_down, target_down, source_fpfh, target_fpfh, \n",
    "                mutual_filter=True, # Improved matching\n",
    "                max_correspondence_distance=thr,\n",
    "                estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "                ransac_n=3, \n",
    "                checkers=[\n",
    "                    o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.85),\n",
    "                    o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(thr)\n",
    "                ], \n",
    "                criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(10000, 0.99)\n",
    "            )\n",
    "\n",
    "            # Update best result if fitness is good and RMSE is lower\n",
    "            if result.fitness > 0.85 and result.inlier_rmse < best_inlier_rmse:\n",
    "                best_fitness = result.fitness\n",
    "                best_inlier_rmse = result.inlier_rmse\n",
    "                best_result = result\n",
    "                best_threshold = thr\n",
    "            \n",
    "            # Early exit if we find a very high-quality match\n",
    "            if best_fitness > 0.95 and best_inlier_rmse < 2.35: \n",
    "                print(f\"Excellent Global Fit Found at Threshold {best_threshold}\")\n",
    "                return best_result, best_threshold\n",
    "            \n",
    "    if best_result is None:\n",
    "        print(\"Warning: RANSAC could not find a fit above 0.85 fitness.\")\n",
    "        # Fallback to the last result generated if nothing met the 0.85 criteria\n",
    "        return result, thr\n",
    "\n",
    "    print(f\"RANSAC Finished. Best Threshold: {best_threshold} | Fitness: {best_fitness:.4f}\")\n",
    "    return best_result, best_threshold\n",
    "\n",
    "\n",
    "# One time local refinement using ICP\n",
    "def run_local_refinement(source, target, initial_transformation, voxel_size):\n",
    "    \"\"\"\n",
    "    Performs ICP registration to refine the alignment found by RANSAC.\n",
    "    \"\"\"\n",
    "    # We use a smaller threshold for ICP to ensure high precision\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    \n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, initial_transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "# Progressive Local Refinement using ICP\n",
    "def run_local_refinement_adaptive(source, target, initial_trans, best_ransac_thr):\n",
    "    \"\"\"\n",
    "    Refines alignment using an iterative ICP loop. \n",
    "    Starts with a coarse threshold and progressively tightens for precision.\n",
    "    \"\"\"\n",
    "    # Define a range of multipliers to tighten the search radius\n",
    "    # multipliers = [1.0, 0.8, 0.5, 0.25]\n",
    "    # multipliers = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    multipliers = [0.6]\n",
    "    thresholds = [best_ransac_thr * m for m in multipliers]\n",
    "    \n",
    "    best_result = None\n",
    "    best_inlier_rmse = float('inf') # Start with the highest possible error\n",
    "    \n",
    "    print(f\"{'Threshold':<12} | {'Fitness':<12} | {'RMSE':<12}\")\n",
    "    print(\"-\" * 45)\n",
    "\n",
    "    for thr in thresholds:\n",
    "        # Execute Point-to-Point ICP\n",
    "        reg_icp = o3d.pipelines.registration.registration_icp(\n",
    "            source, target, thr, initial_trans,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=1000)\n",
    "        )\n",
    "\n",
    "        # Logging the current iteration results\n",
    "        print(f\"{thr:<12.2f} | {reg_icp.fitness:<12.4f} | {reg_icp.inlier_rmse:<12.4f}\")\n",
    "\n",
    "        # Selection Logic: Prioritize lowest RMSE (highest precision) \n",
    "        # as long as the fitness is acceptable (e.g., > 85%)\n",
    "        if reg_icp.fitness > 0.85 and reg_icp.inlier_rmse < best_inlier_rmse:\n",
    "            best_inlier_rmse = reg_icp.inlier_rmse\n",
    "            best_result = reg_icp\n",
    "\n",
    "    # Fallback: if no run met the 85% fitness, return the last result\n",
    "    return best_result if best_result is not None else reg_icp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f14a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Merging and cleaning scans...\n"
     ]
    }
   ],
   "source": [
    "# Main Processing Pipeline\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "DATA_DIR = \"PCD_Data\"\n",
    "SOURCE_PATH = \"workpiece/z_bracket_10000.pcd\" #  CAD model\n",
    "YOLO_POS = [609.17, 73.19, 3.50]              # Initial guess from YOLO\n",
    "YOLO_ANGLE = 88.0                             # Initial angle from YOLO\n",
    "CROP_BOX = [100, 100, 80]                     # Region of interest size\n",
    "\n",
    "\n",
    "# --- 2. Data Preparation ---\n",
    "print(\"Step 1: Merging and cleaning scans...\")\n",
    "source_cloud = o3d.io.read_point_cloud(SOURCE_PATH)\n",
    "target_cloud = merge_multiview_scan(DATA_DIR, YOLO_POS, YOLO_ANGLE, CROP_BOX)\n",
    "# o3d.visualization.draw_geometries([target_cloud], window_name=\"Merged Target Cloud\")\n",
    "\n",
    "# # Get downsampled versions and features for RANSAC\n",
    "# source_down, source_fpfh = preprocess_point_cloud(source_cloud, 10000)\n",
    "# target_down, target_fpfh = preprocess_point_cloud(target_cloud, 10000)\n",
    "# o3d.visualization.draw_geometries([target_down], window_name=\"Downsampled Target Cloud\")\n",
    "\n",
    "\n",
    "# # --- 3. Global Alignment (RANSAC) ---\n",
    "# print(\"Step 2: Running RANSAC Global Registration...\")\n",
    "# ransac_res, best_thr = run_global_registration_adaptive(source_down, target_down, source_fpfh, target_fpfh)\n",
    "# print(ransac_res)\n",
    "\n",
    "# # Visualize RANSAC result\n",
    "# source_temp = copy.deepcopy(source_cloud)\n",
    "# source_temp.transform(ransac_res.transformation)\n",
    "# source_temp.paint_uniform_color([1, 0, 0])\n",
    "# target_down.paint_uniform_color([0, 0.651, 0.929])\n",
    "# o3d.visualization.draw_geometries([source_temp, target_down], window_name=\"RANSAC Result\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8791a78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Running ICP Local Refinement...\n",
      "Threshold    | Fitness      | RMSE        \n",
      "---------------------------------------------\n",
      "4.20         | 0.8981       | 1.7718      \n",
      "RegistrationResult with fitness=8.981000e-01, inlier_rmse=1.771758e+00, and correspondence_set size of 8981\n",
      "Access transformation to get result.\n",
      "==============================\n",
      "Final Position: [609.41933374  73.98370548  -0.76394817]\n",
      "Final Orientation Matrix:\n",
      "[[-0.03382716 -0.99920068 -0.02130084]\n",
      " [ 0.99919832 -0.03335512 -0.0221394 ]\n",
      " [ 0.02141121 -0.02203268  0.99952795]]\n",
      "Fitness: 0.8981\n",
      "RMSE: 1.7718\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Local Alignment (ICP) ---\n",
    "print(\"Step 3: Running ICP Local Refinement...\")\n",
    "icp_res = run_local_refinement_adaptive(source_cloud, target_down, ransac_res.transformation, best_thr)\n",
    "print(icp_res)\n",
    "\n",
    "# --- 5. Extract Final Results ---\n",
    "final_matrix = icp_res.transformation\n",
    "initial_POS = final_matrix[:3, 3] \n",
    "initial_ORI = final_matrix[:3, :3] \n",
    "print(\"=\"*30)\n",
    "print(f\"Final Position: {initial_POS}\")\n",
    "print(f\"Final Orientation Matrix:\\n{initial_ORI}\")\n",
    "print(f\"Fitness: {icp_res.fitness:.4f}\")\n",
    "print(f\"RMSE: {icp_res.inlier_rmse:.4f}\")\n",
    "\n",
    "\n",
    "# --- 6. Final Visualization ---\n",
    "source_final = copy.deepcopy(source_cloud).transform(final_matrix)\n",
    "source_final.paint_uniform_color([1, 0, 0])        # Red: CAD Model\n",
    "target_cloud.paint_uniform_color([0, 0.65, 0.93]) # Blue: Scanned Data\n",
    "o3d.visualization.draw_geometries([source_final, target_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493de6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
